# Pyspark-hadoop-hive-docker

Two steps to create a pyspark hadoop cluster using docker.
1. Build the image
2. Run docker compose command to start the cluster.

